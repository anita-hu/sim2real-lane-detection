# Modified work Copyright (C) 2021 Anita Hu, Sinclair Hudson, Martin Ethier.
# Original work Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).
# Original source: https://github.com/mingyuliutw/UNIT/tree/master/configs

# logger options
log_iter: 500                 # How often do you want to log loss and learning rate values during training

# optimization options
max_epoch: 100                # maximum number of training epochs
save_policy: val              # [val, last] saving based on max validation performance or last epoch
batch_size: 16                # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian, kaiming, xavier, orthogonal]
lr_policy: cos                # learning rate scheduler [constant, step, cos]
iter_per_epoch: 5555          # iterations per epoch
gamma: 0.1                    # how much to decay learning rate
warmup: linear                # warm up type
warmup_iters: 0               # warm up iterations to use if not specified for each model
gan_w: 10                     # weight of adversarial loss
lane_w: 1                     # weight of lane detection loss
mixed_precision: True         # use automatic mixed precision training
multi_gpu: False              # use multi gpu training
random_seed: 42

# model options
trainer: ADA                  # trainer [UNIT, MUNIT]
gen:
  lr: 0.0001                  # initial learning rate
  dim: 64                     # number of filters in the bottommost layer
  norm: bn                    # normalization layer [none, bn, in, ln, adain]
  activ: lrelu                # activation function [relu, lrelu, prelu, selu, tanh]
  n_res: [2, 2]               # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zeros, reflect, replicate]
dis_fea:
  lr: 0.0004                  # initial learning rate
  warmup_iters: 6000          # iterations before introducing feature adversarial loss
  dim: 128                    # number of filters in the bottommost layer
  norm: none                  # normalization layer [none, bn, in, ln]
  activ: lrelu                # activation function [relu, lrelu, prelu, selu, tanh]
  n_layer: 4                  # number of layers in D
  pad_type: reflect           # padding type [zero, reflect]
lane:
  lr: 0.0004                  # initial learning rate
  norm: bn                    # normalization layer [none, bn, in, ln]
  activ: relu                 # activation function [relu, lrelu, prelu, selu, tanh]
  use_aux: True               # use segmentation loss [True, False]
  use_cls: False              # predict lane classes [True, False]
  det_fc_size: 2048           # size of the detection fc layer
  griding_num: 200            # number of column samples
  num_anchors: 18             # number of row anchors [TuSimple/WATO=56, CULane=18]
  num_lanes: 4                # max number of lanes
  sim_loss_w: 0.0             # lane similarity loss
  shp_loss_w: 0.0             # lane shape loss weight

# data options
input_dim_a: 3                # number of image channels [1, 3]
input_dim_b: 3                # number of image channels [1, 3]
input_height: 288             # resized image height
input_width: 800              # resized image width

# By convention, dataset A will be simulation, labelled data, while dataset B will be real-world without labels
dataset: CULane                       # real-world dataset [CULane, TuSimple]
dataA_root: /datasets/WATO_CULane     # dataset folder location for simulation images with labels
dataB_root: /datasets/CULane          # dataset folder location for real-world images without labels
